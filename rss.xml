<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Graham Wheeler's Random Forest</title><link>https://www.grahamwheeler.com/</link><description>Stuff about stuff</description><atom:link href="https://www.grahamwheeler.com/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 13 Jul 2018 03:01:54 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The "Tyranny" of Metrics</title><link>https://www.grahamwheeler.com/posts/tyranny-of-metrics.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/images/metrics-dashboard.jpg"&gt;&lt;img alt="image" src="https://www.grahamwheeler.com/images/metrics-dashboard.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jerry Muller recently wrote a popular book titled &lt;a href="https://www.amazon.com/gp/product/0691174954/"&gt;"The Tyranny of Metrics"&lt;/a&gt;. He makes a number of good arguments for why metrics, if not used properly, can have unintended consequences. For example, the &lt;em&gt;body count&lt;/em&gt; metric that the US military optimized for in the Vietnam war caused enormous damage while losing the hearts and minds of the populace and resulting in an ignominious defeat. Muller argues that metrics are too often used as a substitute for good judgment. The book is an excellent read.&lt;/p&gt;
&lt;p&gt;So should we be ignoring metrics? Clearly not, but we need to be cognizant of what metrics we choose and how we use them. We should also distinguish between things which can meaningfully be measured quantitatively versus things that are more suited to qualitative analyses. And we should be wary of metrics being used as an instrument of control by those far removed from the "trenches", so to speak.&lt;/p&gt;
&lt;p&gt;Assuming that we have a problem that can meaningfully be measured in a quantitative way, we need to make sure our metrics meet a number of criteria to be useful. Here are some guidelines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;metrics should be &lt;em&gt;actionable&lt;/em&gt;: they should tell you what you should be doing next. If you can't answer the question of what you would do if a metric changed then its probably not a good metric.&lt;/li&gt;
&lt;li&gt;metrics should be &lt;em&gt;clearly and consistently defined&lt;/em&gt;: changing the definition of a metric can invalidate all the historical record and is very costly. Do the work upfront to make sure the metric is well-defined and measuring what you want, and then don't change the definition unless you can do so retroactively. Ensure that the metric is defined and used consistently across the business.&lt;/li&gt;
&lt;li&gt;metrics should be &lt;em&gt;comparative&lt;/em&gt; over time (so it is useful to aggregate these over fixed periods like week-over-week or monthly - but be cognizant of seasonal effects).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;ratios are often better than absolute values&lt;/em&gt; as they are less affected by exogenous factors. Similarly, &lt;em&gt;trends are more important than absolute values&lt;/em&gt;. &lt;/li&gt;
&lt;li&gt;metrics are most useful if they are &lt;em&gt;leading indicators&lt;/em&gt; so you can take action early. For example, &lt;a href="https://en.wikipedia.org/wiki/Work_in_process"&gt;Work in Progress (WIP)&lt;/a&gt; is a leading indicator, while &lt;a href="https://en.wiktionary.org/wiki/cycle_time"&gt;cycle time&lt;/a&gt; is a trailing indicator. Think of a highway: you can quickly tell if it is overcrowded, before you can tell how long your commute has been delayed.&lt;/li&gt;
&lt;li&gt;good metrics make up a &lt;em&gt;hierarchy&lt;/em&gt;: your team's metrics should roll up to your larger division's metrics which should roll up to top-level business metrics.&lt;/li&gt;
&lt;li&gt;metrics should be &lt;em&gt;in tension&lt;/em&gt;: you should try to find metrics that cannot be easily gamed without detrimentally affecting other metrics. Let's say I have a credit risk prediction model and my metric is the number of customers I predict are not credit risks but that default on their debt. I can just predict that every customer is high risk and my metric will look great, but that's bad for the business. So I need another metric that is in tension with this, such as the number of good customers I deny credit to, which must be minimized. More generally in prediction models we use the combination of &lt;a href="https://en.wikipedia.org/wiki/Precision_and_recall"&gt;&lt;em&gt;precision&lt;/em&gt; and &lt;em&gt;recall&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;metrics should &lt;em&gt;capture different classes of attributes&lt;/em&gt; such as quality and throughput.&lt;/li&gt;
&lt;li&gt;you need to know when a deviation in a metric is a cause for concern. A good general guideline is that if a metric deviates more than two standard deviations from the mean over some defined period, you should start paying attention, and more than three standard deviations you should be alarmed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks to &lt;a href="https://www.linkedin.com/in/saujanya/"&gt;Saujanya Shrivastava&lt;/a&gt; for many fruitful discussions over our metrics from which these guidelines emerged.&lt;/p&gt;&lt;/div&gt;</description><guid>https://www.grahamwheeler.com/posts/tyranny-of-metrics.html</guid><pubDate>Fri, 13 Jul 2018 01:04:00 GMT</pubDate></item><item><title>Managing Engineering and Data Science Agile Teams</title><link>https://www.grahamwheeler.com/posts/managing-data-science-and-engineering.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div&gt;&lt;p&gt;It is very common in modern software engineering organizations to use agile approaches to managing teamwork. At both Microsoft and eBay teams I have managed have used Scrum, which is a reasonably simple and effective approach that offers a number of benefits, such as timeboxing, regular deployments (not necessarily continuous but at least periodic), a buffer between the team and unplanned work, an iterative continuous improvement process through retrospectives, and metrics that can quickly show whether the team is on track or not.&lt;/p&gt;
&lt;p&gt;Data science work does not fit quite as well into the Scrum approach. I've heard of people advocating for its use, and even at my current team we initially tried to use Scrum for data science, but there are significant challenges. In particular, I like my Scrum teams to break work down to user stories to a size where the effort involved is under two days (ideally closer to half a day). Yes, we use story points, but once the team is calibrated fairly well its still easy to aim for this. Trying to do this for data science work is much harder, especially when it is research work in building new models which is very open-ended.&lt;/p&gt;
&lt;p&gt;The approach I have taken with my team is an interesting hybrid that seems to be working quite well and is worth sharing.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/managing-data-science-and-engineering.html"&gt;Read moreâ€¦&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Data Science</category><category>Management</category><guid>https://www.grahamwheeler.com/posts/managing-data-science-and-engineering.html</guid><pubDate>Wed, 04 Jul 2018 04:53:00 GMT</pubDate></item><item><title>Basic Machine Learning with SciKit-Learn</title><link>https://www.grahamwheeler.com/posts/basic-machine-learning.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;em&gt;This is the fourth post in a series based off my &lt;a href="https://www.grahamwheeler.com/posts/(https:/github.com/gramster/pythonbootcamp"&gt;Python for Data Science bootcamp&lt;/a&gt; I run at eBay occasionally. The other posts are:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/python-crash-course.html"&gt;a Python crash course&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/using-jupyter.html"&gt;using Jupyter&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html"&gt;exploratory data analysis&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post we will look into the basics of building ML models with Scikit-Learn. Scikit-Learn is the most widely used Python library for ML, especially outside of deep learning (where there are several contenders and I recommend using Keras, which is a package that provides a simple API on top of several underlying contenders like TensorFlow and PyTorch).&lt;/p&gt;
&lt;p&gt;We'll proceed in this fashion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;give a brief overview of key terminology and the ML workflow&lt;/li&gt;
&lt;li&gt;illustrate the typical use of SciKit-Learn API through some simple examples&lt;/li&gt;
&lt;li&gt;discuss various metrics that can be used to evaluate ML models&lt;/li&gt;
&lt;li&gt;dive deeper with some more complex examples&lt;/li&gt;
&lt;li&gt;look at the various ways we can validate and improve our models&lt;/li&gt;
&lt;li&gt;discuss the topic of feature engineering - ML models are good examples of "garbage in, garbage out", so cleaning our data and getting the right features is important&lt;/li&gt;
&lt;li&gt;finally, summarize some of the main model techniques and their pros and cons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/basic-machine-learning.html"&gt;Read moreâ€¦&lt;/a&gt; (42 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Data Science</category><category>Jupyter</category><category>Machine Learning</category><category>Pandas</category><category>Python</category><guid>https://www.grahamwheeler.com/posts/basic-machine-learning.html</guid><pubDate>Sun, 29 Apr 2018 23:40:00 GMT</pubDate></item><item><title>Exploratory Data Analysis with NumPy and Pandas</title><link>https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;em&gt;This is the third post in a series based off my &lt;a href="https://github.com/gramster/pythonbootcamp"&gt;Python for Data Science bootcamp&lt;/a&gt; I run at eBay occasionally. The other posts are:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/python-crash-course.html"&gt;a Python crash course&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/using-jupyter.html"&gt;using Jupyter&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/basic-machine-learning.html"&gt;introductory machine learning&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is an introduction to the NumPy and Pandas libraries that form the foundation of data science in Python. These libraries, especially Pandas, have a large API surface and many powerful features. There is now way in a short amount of time to cover every topic; in many cases we will just scratch the surface. But after this you should understand the fundamentals, have an idea of the overall scope, and have some pointers for extending your learning as you need more functionality.&lt;/p&gt;
&lt;h3 id="Introduction"&gt;Introduction&lt;a class="anchor-link" href="https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html#Introduction"&gt;Â¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We'll start by importing the numpy and pandas packages. Note the "as" aliases; it is conventional to use "np" for numpy and "pd" for pandas. If you are using Anaconda Python distribution, as recommended for data science, these packages should already be available:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We are going to do some plotting with the matplotlib and Seaborn packages. We want the plots to appear as cell outputs inline in Jupyter.
To do that we need to run this next line:
&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html"&gt;Read moreâ€¦&lt;/a&gt; (94 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Data Science</category><category>Jupyter</category><category>Pandas</category><category>Python</category><guid>https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html</guid><pubDate>Sat, 28 Apr 2018 19:40:00 GMT</pubDate></item><item><title>Using Jupyter</title><link>https://www.grahamwheeler.com/posts/using-jupyter.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;em&gt;This is the second post in a series based off my &lt;a href="https://github.com/gramster/pythonbootcamp"&gt;Python for Data Science bootcamp&lt;/a&gt; I run at eBay occasionally. The other posts are:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/python-crash-course.html"&gt;a Python crash course&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html"&gt;exploratory data analysis&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/basic-machine-learning.html"&gt;introductory machine learning&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; is an interactive computing environment that allows users to create heterogeneous documents called &lt;em&gt;notebooks&lt;/em&gt; that can mix executable code, &lt;a href="https://en.wikipedia.org/wiki/Markdown"&gt;markdown&lt;/a&gt; text with &lt;a href="https://www.mathjax.org/"&gt;MathJax&lt;/a&gt;, multimedia, static and interactive charts, and more. A notebook is typically a complete and self-contained record of a computation, and can be converted to various formats and shared with others. Jupyter thus supports a form of &lt;a href="https://en.wikipedia.org/wiki/Literate_programming"&gt;literate programming&lt;/a&gt;. Several of the posts on this blog, including this one, were written as Jupyter notebooks. Jupyter is an extremely popular tool for doing data science in Python due to its interactive nature, good support for iterative and experimental computation, and ability to create a finished artifact combining both scientific text (with math) and code. It's easiest to start to understand this by looking at an &lt;a href="http://nbviewer.jupyter.org/url/norvig.com/ipython/Economics.ipynb"&gt;example&lt;/a&gt; of a finished notebook.&lt;/p&gt;
&lt;p&gt;Jupyter the application combines three components:
&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/using-jupyter.html"&gt;Read moreâ€¦&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Data Science</category><category>Jupyter</category><category>Python</category><guid>https://www.grahamwheeler.com/posts/using-jupyter.html</guid><pubDate>Wed, 18 Apr 2018 04:35:00 GMT</pubDate></item><item><title>The 5-Factor Model of Personality</title><link>https://www.grahamwheeler.com/posts/personality-and-relationships1.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Shankar Vedantam has a great NPR show/podcast, &lt;a href="https://www.npr.org/podcasts/510308/hidden-brain"&gt;"The Hidden Brain"&lt;/a&gt;, and occasional appearances on NPR's All Things Considered.  In December he had a show on Evaluating Personality Tests. It was enjoyable, especially the Harry Potter Sorting Hat references, but I felt it was a missed opportunity because of the focus on Myers-Briggs, and the fact that he mentioned the Big-5 model only in passing.&lt;/p&gt;
&lt;p&gt;In fact, Myers-Briggs is not taken very seriously in the psychology world, and Vedantam surprised me with spending so much time on it, given his show's focus on research in psychology. On the other hand, the Big-5 model is taken quite seriously, with many studies and papers based on it and evaluating it in various contexts (take a look, for example, at the Oxford University Press book I link to at the end of this post).&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://www.npr.org/2017/12/11/569815338/evaluating-personality-tests"&gt;short form NPR segment&lt;/a&gt;, this was the section on Big-5 in its entirety:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;VEDANTAM: Many personality researchers put greater stock in a test known as the Big Five [vs Myers-Briggs]. Grant says the Big Five has lots of peer reviewed data to back it up.&lt;/p&gt;
&lt;p&gt;GRANT: We can predict your job performance, your effectiveness in a team with different collaborators, your likelihood of sticking around in a job versus leaving as well as your probability of your marriage surviving, depending on the personality fit between you and your spouse.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/personality-and-relationships1.html"&gt;Read moreâ€¦&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Management</category><category>Psychology</category><guid>https://www.grahamwheeler.com/posts/personality-and-relationships1.html</guid><pubDate>Mon, 16 Apr 2018 04:35:00 GMT</pubDate></item><item><title>A Python Crash Course</title><link>https://www.grahamwheeler.com/posts/python-crash-course.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I've been teaching &lt;a href="https://github.com/gramster/pythonbootcamp"&gt;a crash course in data science with Python&lt;/a&gt;, which starts off with learning Python itself. The target audience is Java programmers (generally senior level) so its assumed that things like classes and methods are well understood. The focus is mostly on what is different with Python. I teach it using Jupyter notebooks but the content is useful as a blog post too so here we go.&lt;/p&gt;
&lt;p&gt;The other parts are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/using-jupyter.html"&gt;using Jupyter&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/exploratory-data-analysis-with-numpy-and-pandas.html"&gt;exploratory data analysis&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://www.grahamwheeler.com/posts/basic-machine-learning.html"&gt;introductory machine learning&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Introduction"&gt;Introduction&lt;a class="anchor-link" href="https://www.grahamwheeler.com/posts/python-crash-course.html#Introduction"&gt;Â¶&lt;/a&gt;&lt;/h3&gt;&lt;h4 id="Python's-Origins"&gt;Python's Origins&lt;a class="anchor-link" href="https://www.grahamwheeler.com/posts/python-crash-course.html#Python's-Origins"&gt;Â¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Python was conceived in the late 1980s, and its implementation began in December 1989 by Guido van Rossum at Centrum Wiskunde &amp;amp; Informatica (CWI) in the Netherlands as a successor to the ABC language. It takes its name from Monty Python's Flying Circus.&lt;/p&gt;
&lt;p&gt;Python is a dynamic language but is strongly typed (i.e. variables are untyped but refer to objects of fixed type).
&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/python-crash-course.html"&gt;Read moreâ€¦&lt;/a&gt; (58 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Programming</category><category>Python</category><guid>https://www.grahamwheeler.com/posts/python-crash-course.html</guid><pubDate>Fri, 13 Apr 2018 03:10:00 GMT</pubDate></item><item><title>Blogging again</title><link>https://www.grahamwheeler.com/posts/blogagain.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div&gt;&lt;p&gt;Well, it's been quite a while since I last blogged. My Zite project is not dead; it's actually up and 
running well as a personal aggregator but not ready for multi-user access, and I'm not sure when it
might be. But I've been feeling a bit of an itch to start blogging again so here goes.&lt;/p&gt;
&lt;p&gt;I have some material already lined up: I've been teaching an introductory data science bootcamp at
work and thought the notebooks from that could be useful blog posts in and of themselves. So I'll
start slowly publishing those while I write some new material. I'm also going to expand the scope 
of this blog; I'll still cover some tech topics but I',m going to fold in the content from my
dormant math blog and retire it; this may inspire me to do some math blogging again. And I'll be 
throwing in some stuff on management and psychology too. So this will be a mishmash living up to 
the random forest name. I'll use categories to make it more accessible for those only interested
in specific topics.&lt;/p&gt;
&lt;p&gt;More soon!&lt;/p&gt;&lt;/div&gt;</description><guid>https://www.grahamwheeler.com/posts/blogagain.html</guid><pubDate>Thu, 12 Apr 2018 04:00:00 GMT</pubDate></item><item><title>Building a Zite Replacement (Part 11)</title><link>https://www.grahamwheeler.com/posts/zite-replacement-11.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div&gt;&lt;p&gt;It's been a while since I worked on this but it is still on my mind a lot. I've been mulling over ways to improve categorization without the semi-supervised tweaking I've had to do.&lt;/p&gt;
&lt;p&gt;Just to recap, currently this is what I am doing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I have a bunch of 'category exemplars', which are sets of key terms associated with a category. These are the things which currently require some manual work;&lt;/li&gt;
&lt;li&gt;for each article, I extract the plain text, normalize capitalization, remove &lt;a href="https://en.wikipedia.org/wiki/Stop_words"&gt;stop words&lt;/a&gt;, then use &lt;a href="https://en.wikipedia.org/wiki/Tf-idf"&gt;tf-idf&lt;/a&gt; to extract the set of most significant terms (I'm not yet doing &lt;a href="https://en.wikipedia.org/wiki/Stemming"&gt;stemming&lt;/a&gt; although I'll probably start);&lt;/li&gt;
&lt;li&gt;I then use a &lt;a href="https://en.wikipedia.org/wiki/Metric_(mathematics)"&gt;distance metric&lt;/a&gt; from the exemplars to assign category scores to the articles. Provided the score exceeds a threshold the article will be considered to be in the category.
&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/zite-replacement-11.html"&gt;Read moreâ€¦&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description><guid>https://www.grahamwheeler.com/posts/zite-replacement-11.html</guid><pubDate>Sat, 23 Apr 2016 16:15:00 GMT</pubDate></item><item><title>Using Jupyter as a Music Notebook</title><link>https://www.grahamwheeler.com/posts/using-jupyter-as-a-music-notebook.html</link><dc:creator>Graham Wheeler</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I recently started playing guitar again after a long absence and wanted to start making some notes in a digital form. Unfortunately, I didn't find any good tools. There is TeX of course, which can do anything, but I was hoping for something a bit more WYSIWYGy. There are some very good tools available for musical scores (MuseScore, Frescobaldi), but I want something that is more like a traditional notebook with lots of notes interspersed with occasional musical notation (in both traditional and tablature forms).&lt;/p&gt;
&lt;p&gt;So an obvious potential candidate is Jupyter (nee IPython), but it has no support for musical notation out of the box. But it is doable and in this post I'll walk through how I got it to work on my Mac. This is also my first attempt at using a Jupyter notebook as my blog post in Nikola so I'm kiling two birds with one stone.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.grahamwheeler.com/posts/using-jupyter-as-a-music-notebook.html"&gt;Read moreâ€¦&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Jupyter</category><category>Python</category><guid>https://www.grahamwheeler.com/posts/using-jupyter-as-a-music-notebook.html</guid><pubDate>Sat, 27 Feb 2016 20:00:00 GMT</pubDate></item></channel></rss>